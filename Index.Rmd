---
title: "Modélisation statistique avec R"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
    df_print: paged
runtime: shiny_prerendered
description: >
  Modélisation statistique avec R.
---


```{r setup, include=FALSE}
library(learnr)
library(tidyverse)
library(DT)
library(lmerTest)
library(multcomp)
library(multcompView)
library(emmeans)
library(MuMIn)

fallow <- read.csv("Fallow N2.csv")

linreg_mod<-lm(yield~striga,data=fallow)
anova_mod<-lm(yield~treat,data=fallow)
mod_mixte<-lmer(yield~treat+(1|rep),data=fallow)

```

## Introduction

Dans ce tutoriel, nous allons voir comment utiliser certains des modéles statistique les plus couramment utilisés, notamment lorsqu'il s'agit d'analyser des donnees issues de recherches en agriculture. Nous allons parler de :

1. Modèle de régression linéaire
2. Modèle d'analyse de variance (ANOVA).
3. Modèles linéaires mixtes et généralisés.

Vous constaterez rapidement que le code requis dans R pour toutes ces approches de modélisation est très similaire. En fait, tous ces modèles font partie du même cadre général de modélisation, qui s'étend à presque tous les modèles courants que vous pourriez vouloir ajuster.


![](https://youtu.be/AYLY10wk6PY)

Dans la vidéo ci-dessus, j'explique plus généralement ce que l'on entend par modèle et explique l'interet d'aller au-delà du simple modèle de régression linéaire. Car dans de nombreux cas, celui-ci n'est pas suffisant pour avoir un modèle qui explique bien nos données et permette de repondre aux questions que l'on se pose. Mais bien que la theorie statistique devient en general de plus en plus compliquées a mesure que les modeles deviennent plus complexes, le code R permettant de spécifier et étudier ces modèles complexes, lui, n'est en fait pas beaucoup plus compliqué que pour les modeles simples. Cela signifie qu'avec R, nous devrions pouvoir apprendre à analyser nos données, sans avoir a nous restraindre sur les modeles que nous pouvons utiliser. Nous devrions pouvoir utiliser le modele qui ***convient*** a nos objectifs et nos données.


## Données

Les données utilisées dans cet exemple proviennent d'une étude menée dans l'Est de la Zambie ayant pour objectif principal d'améliorer l'efficacité des jachères naturelles en utilisant des arbres appropriés qui favorisent la régénération de la fertilité du sol dans les périodes de jachère.

Les données ont été chargées dans R et assignées à un objet appelé `fallow`.

Le design de l'expérience est un RCBD (design en blocs complets randomisés) avec 4 blocs et 9 traitements. Si vous regardez les données ci-dessous, vous verrez que nous avons des données concernant le rendement (la colonne `yield` dans les données) et le quantite de striga (`striga`) pour chaque parcelle (la colonne `plot` ), d'un bloc (la colonne `rep`), ayant subi un traitement spécifique (la colonne `trait`). 

```{r,echo=FALSE}
DT::datatable(fallow)
```


## Packages utilisés

Dans ce tutoriel, nous utiliserons quatre nouveaux packages: `emmeans`,` multcomp`, `lmerTest` et` MuMIn`; de plus, nous utiliserons certains des packages que nous avons utilisés régulièrement jusqu'à présent dans ce cours `dplyr` et` ggplot2`. Assurez-vous qu'ils sont tous installés et chargés avant d'exécuter l'un des codes sur votre propre ordinateur.

```
library(ggplot2)
library(dplyr)

library(lmerTest)
library(multcomp)
library(multcompView)
library(emmeans)
library(MuMIn)

```


## Modèle de régression linéaire

Le premier type de modèle que nous allons étudier est un modèle de régression linéaire, afin de déterminer s'il y a une relation linéaire entre `yield` et `striga`.

Nous supposons que vous avez entendu parler des modèles de regression linéaire. Voila une vidéo de "Crash Course Statistics" qui peut  aider a se rappeler de comment marche cette méthodologie.
![](https://www.youtube.com/watch?v=WWqE7YHR4Jc) 

Comme nous l'avons appris dans les modules précédents, la première chose à faire est d'explorer nos données et d'examiner quelques résumés statistiques et graphiques !

### Analyse exploratoire des données

Pour examiner les données a partir de résumés statistiques, nous pourrions faire deux choses. Premièrement, nous pourrions calculer une corrélation, en utilisant la fonction `cor`. Pour utiliser cette fonction, nous devons spécifier les deux variables avec lesquelles nous voulons calculer la corrélation.

```{r cor1, exercise=TRUE}
cor(fallow$yield,fallow$striga)
```
Une valeur de -0,339 suggère une corrélation négative de force moyenne entre ces variables. Mais la corrélation n'est pas une valeur particulièrement informative - l'ajustement d'un modèle linéaire nous fournit les mêmes informations, et beaucoup d'autres choses !

Nous pourrions également calculer des résumés statistiques tel que la moyenne du rendement pour différentes catégories de la variable striga. Nous pourrions utiliser `mutate()` pour créer une nouvelle variable, et dans` mutate()` utiliser la fonction` cut() `pour diviser `striga` en plusieurs groupes afin de définir nos catégories. Nous pourrons alors utiliser `group_by()` sur cette nouvelle variable, puis `summarise()` pour calculer nos moyennes de rendement. Dans la fonction `cut()` ont doit définir les valeurs qui délimitent nos nouvelles catégories - notez que la limite inférieure est exclue par défaut, nous devons donc nous assurer que nous incluons l'option` include.lowest = TRUE` pour nous assurer que la quantité de striga "0" est incluse dans la premiere catégorie

```{r sumstats, exercise=TRUE}
fallow %>%
  mutate(striga_grp=cut(striga,breaks=c(0,25,250,9999),include.lowest = TRUE))%>%
    group_by(striga_grp) %>%
      summarise(mean(yield),n())
```
Nous pouvons voir une réduction du rendement moyen - de 3,6t/ha dans le groupe ayant la plus faible quantite de striga, à 2,88t/ha dans le groupe ayant la quantite la plus élevé de striga. `cut` et le nombre de groupes à choisir est un peu arbitraire. J'ai choisi des nombres assez ronds et je suis allé parti sur trois nouvelles catégories concernant la quantite de striga - de 0 à 25, de 26 à 250, et plus de 250.

### Graphiques

Examinons le type graphique le plus 'évidente' lorsque nous considérons ce type de relation entre deux variables continues - le nuage de points de la quantite de striga par rapport au rendement. Nous mettrons `yield` (le rendement) sur l'axe des y et `striga` sur l'axe des x. En effet, nous considérons le rendement comme notre variable "réponse" et la quantite de striga comme notre variable "prédictive". Nous pensons qu'il est plus probable qu'une infestation accrue de striga entraînera une baisse des rendements plutôt que l'inverse (bien qu'il y ait débat à ce sujet!).

Voyez si vous pouvez reproduire le graphique ci-dessous en utilisant la `geom_` appropriée de` ggplot2`.

```{r plot0, echo=FALSE}
ggplot(data=fallow,aes(y=yield,x=striga))+
  geom_point()
```

```{r plot1, exercise=TRUE}

```

```{r plot1-solution}
ggplot(data=fallow,aes(y=yield,x=striga))+
  geom_point()
```

Pour nous aider à mieux comprendre cette relation, nous pouvons ajouter une couche "geom_" supplémentaire en utilisant `geom_smooth` qui ajoutera une ligne de tendance a notre graphique. Par défaut, la courbe de tendance est calculée à partir d'un 'modèle additif généralisé' qui est une similaire à une moyenne mobile.
Cependant, nous pouvons demander a R d'utilsier un modèle de régression linéaire simple pour calculer notre tendance sous forme d'une ligne droite, en utilisant l'option `method = lm`.

```{r plot2, exercise=TRUE}
ggplot(data=fallow,aes(y=yield,x=striga))+
  geom_point()+
    geom_smooth(method="lm")
```

On dirait qu'une ligne droite semble relativement bien adaptée a notre relation. Nous avons beaucoup de points avec un faible nombre de striga - mais à mesure que nous augmentons le nombre de striga, le rendement semble décroitre de facon à peu près linéaire. La plupart des observations ont un faible nombre de striga, et parmi ces observations, la variabilité du rendement est élevée, mais les quelques observations avec un nombre de striga plus élevé semblent toutes avoir des rendements relativement faibles.

### Ajuster le modèle

Pour explorer un peu plus le modèle que nous avons utilisé avec `geom_smooth`, nous devons ajuster formellement le modèle dans R. Nous le faisons en utilisant la commande` lm() `. Notez que la fonction que nous utilisons est écrite avec la lettre `l` et non le nombre `1`. "lm" signifie "linear model" (modèle linéaire). La syntaxe de la fonction `lm()` est très similaire à ce que nous avons vu dans le module précédent pour le tests t, avec une variable de réponse, le tilde, puis la variable explicative. Et puis le nom du jeu de données que l'on renseigne après.


```{r lm1, exercise=TRUE}
lm(yield~striga,data=fallow)
```

La sortie ici ne nous fournit que deux informations:

* "Call" - répétant simplement le modèle que nous avons spécifié
* "Coefficients": nous indiquant les valeurs des paramètres
 
Une régression linéaire suit l'équation d'une ligne droite y = B0 + B1x. Vous avez peut-être appris cette même équation par y = a + bx ou y = mx + c; selon l'endroit et le moment où vous avez étudié cela. En statistique, on ajoute aussi un terme supplémentaire $\epsilon$, qui représente la variabilité résiduelle de cette relation. Si tous les points se trouvaient parfaitement sur la ligne, alors il n'y aurait pas besoin du terme $\epsilon$, mais en réalité, nous avons toujours une variabilité qui doit être prise en compte.

Les coefficients que R nous donnent sont l'ordonnée à l'origine (B0): 3,43, et la valeur de notre coefficient directeur ou pente (B1): -0,00059

Notre modèle de regression lineaire serait donc:

rendement = 3,43 - 0,00059 * nombre de striga + $\epsilon$

La valeur de l'ordonnée à l'origine est interprétée comme la valeur moyenne attendue de la variable réponse lorsque toutes les variables explicatives sont égales à zéro. Donc, pour une parcelle sans striga, on s'attend à voir un rendement moyen de 3,43 t/ha.

La valeur de la pente représente le changement que nous nous attendons à voir dans la variable réponse lorsque il y a une augmentation d'une unité de la variable explicative. Ainsi, pour chaque striga supplémentaire observée, il semble en moyenne y avoir une réduction du rendement de 0,00059 t/ha.

Pour l'instant, le resultat de la fonction `lm()` ne nous a rien dit sur le terme d'erreur, $\epsilon$.

Cependant, nous pouvons obtenir beaucoup plus d'informations a propos de notre modèle ! R est un peu différent de nombreux autres logiciels qui produisent de nombreux tableaux différents lorsque vous créez un modèle. Dans R, vous devez demander spécifiquement ce que vous voulez que R vous affiche a propos de votre modèle.

C'est ce que nous allons faire, mais avant ca, nous devons sauver l'ajustement de notre modèle dans un objet. Je choisis de lui donner le nom `linreg_mod`.


```{r lm2, exercise=TRUE}
linreg_mod<-lm(yield~striga,data=fallow)

```

### Résumé de l'ajustement du modèle

`summary()` nous fournit de nombreuses informations statistiques utiles concernant l'ajustement de notre modèle, notamment les ecarts-types et p-values associees aux coefficients.

```{r lm2s, exercise=TRUE}
summary(linreg_mod)

```

L'un des resultats fourni par `summary ()` nous permet de compléter le modèle de régression linéaire, car il fournit la valeur de sigma, également connue sous le nom d'erreur standard résiduelle. Dans notre terme d'erreur, $\epsilon$, il s'agit de l'écart type des valeurs résiduelles. Parce que nous faisons un modèle linéaire simple, nous supposons que nos résidus sont normalement distribués avec une moyenne de 0. Nous vérifierons bientot si cette hypothèse semble valide.

Les resultats nous indiquent que la relation entre le nombre de striga et le rendement semble statistiquement significative, p = 0,043.

L'ordonnée à l'origine est également associee a une p-value significative. Mais cela n’a que peu d’intérêt. L'hypothèse nulle qui génère cette p-value est que l'ordonnée à l'origine est égale à 0. En d'autres termes, l'hypothèse nulle est que la valeur de rendement attendue en l'absence de striga est de 0 t/ha. Il n'est pas vraiment surprenant que les donnees nous indiquent que ce n'est certainement pas le cas !

Si nous regardons de nouveau le resultat de la fonction `summary()`, nous pouvons également voir que 11,5% de la variabilité du rendement peut être expliquée par la relation lineaire avec la quantite de striga (Multiple R-Squared / r.squared). Vous pouvez lire un peu plus sur le r-carré, et pourquoi le r-carré ajusté est également une métrique utile à considérer [ici](https://thestatsgeek.com/2013/10/28/r-squared-and-adjusted-r-squared/).


Comme avec la fonction `t.test`, l'argument data vient après la formule. Donc, si nous voulions utiliser un "pipe" `%>%` avec `lm()` nous aurions besoin de spécifier `data=.` dans la fonction `lm()`. Une chose qui est assez pratique est nous pouvons aussi utiliser le pipe *apres* l'ajustement du modèle, vers d'autres fonctions. En general, nous voulons cependant plutot enregistrer l'ajustement de nos modèles plutôt que d'utiliser des pipes, parce que le calcul du modèle peut prendre un peu de temps si nous avons un jeu de données volumineux ou un modèle compliqué. Et nous voulons souvent faire plusieurs choses différentes avec notre ajustement. Mais cela reste utile de savoir que l'on peut utiliser l'operateur pipe ici aussi :

```{r lmpipe, exercise=TRUE}
fallow %>%
  lm(yield~striga,data=.) %>%
    summary()
```





### Vérification du modèle

Nous devrions également vérifier nos graphiques résiduels pour évaluer la validité du modèle. Cela vaut la peine de récapituler ou d'apprendre à interpréter ces graphiques, car cela peut prendre un peu de pratique pour savoir les analyser. "Statistics by Jim" a un article utile pour cela: https://statisticsbyjim.com/regression/ols-linear-regression-assumptions/

```{r chkplot, exercise=TRUE}
plot(linreg_mod)
```
Ces graphiques nous permettent de vérifier un certain nombre de conditions de validité clés liées à  
* la linéarité de la tendance (y a-t-il une tendance entre les valeurs résiduelles et le graphique ajusté? Si oui, alors la lien entre nos variables n'est peut-etre pas lineaire);  
* l'homogénéité de la variance (y a-t-il une tendance visible dans le graphique "scale-location"?);  
* la normalité approximative des résidus (les points du graphique "normal QQ" suivent-ils approximativement une ligne droite);  
* et l'existence de points extremes ayant une grosse influence (existe-t-il des résidus normalisés >3 ou des points situés hors de l'entonnoir dans le graphique "résidus vs leverage").

Dans notre cas, les quatre graphiques semblent satisfaisants.

Cependant, il y a une condition de validité tres  importante qui ne peut être évaluée à partir de ces graphiques : mes points sont-ils tous indépendants ? Dans notre cas, la réponse est certainement "non", ce qui rend le modèle non valide. En effet, lorsque nous avons choisi notre modèle ici, nous avons complètement ignoré la structure de l'expérience - nous n'avons pas pris en compte les différents traitements (qui constituent une source de dépendance) et nous n'avons pas pris en compte les blocs utilisés dans cette expérience (qui constituent une autre source de dépendance).

Ainsi, le modèle que nous avons utilisé ici n'est probablement pas valable pour comparer les rendements et la quantite de strigas. Dans l'exercice, nous allons chercher à améliorer ce modèle. Mais le code que nous avons utilisé dans cette partie sera tout a fait correcte et vous pourrez l'utiliser pour d'autres situations ou vous voudrez effectuer une régression linéaire.

## Analyse de la Variance

Une régression linéaire simple peut être utilisée lorsque nous avons une variable réponse quantitative (comme `yield`) et une variable prédictive quantitative (comme `striga`). Souvent, lorsqu'on etudie les statistiques, on nous enseigne l'analyse de la variance (ANOVA) séparément, lorsque nous avons une variable de réponse quantitative et une variable prédictive catégorielle, Cependant, mathématiquement, théoriquement et en termes de traitement avec R, ce sont deux méthodes identiques. Il y a une belle explication à cela [ici](https://www.theanalysisfactor.com/why-anova-and-linear-regression-are-the-same-analysis/). 

Ces deux méthodes sont des exemples de 'modèles linéaires' (ou GLM, pour general linear model), et pour ajuster un modèle ANOVA, nous utilisons presque toutes les mêmes fonctions que celles utilisées dans la section précédente. Nous utiliserons quelques autres fonctions pour explorer les résultats de notre modèle cependant, et celles-ci utiliseront des packages supplémentaires pour nous aider à faire des interprétations sur les differences entre les categories. Nous utiliserons les packages `emmeans` et `multcomp` pour estimer les moyennes marginales, puis effectuer une analyse "mean separation" (separation de la moyenne).

Commençons donc et effectuons une ANOVA a un facteur (one-way ANOVA) pour comparer s'il existe des différences de rendement entre les différents traitements.

### Summary Statistics

Lorsque nous avons un facteur definissant des groupes comme `treat` (traitement), les résumés statistiques et les graphiques que nous pourrions vouloir créer sont très similaires à ce que nous avons fait dans les autres tutoriel. Essayez de reproduire le tableau ci-dessous montrant la moyenne et l'écart type du rendement pour chaque traitement.

```{r anovastats0, echo=FALSE}
fallow %>%
  group_by(treat) %>%
    summarise(mean(yield),sd(yield))
```

```{r anovastats, exercise=TRUE}


```

```{r anovastats-solution}
fallow %>%
  group_by(treat) %>%
    summarise(mean(yield),sd(yield))
```

### Résumés graphiques

Étant donné que nous n'avons que quatre observations par traitement, il n'est peut être pas approprié d'utiliser des boîte à moustaches, car le nombre d'observations par groupe est très faible. Effectuer un graphique en nuage de points à l'aide d'une géométrie 'point' est probablement un meilleur moyen de visualiser les données


```{r points, exercise=TRUE}
ggplot(fallow,aes(y=yield,x=treat))+
  geom_point()
```

Les résumés statistiques et graphique ci-dessus nous montrent assez clairement que le traitement "1 S.sesban" fournit des rendements plus élevés que les autres traitements. Le rendement le plus bas pour ce traitement est toujours supérieur à celui de n'importe lequel des rendements de n'importe lequel des autres traitements. Parmi les 8 autres traitements, nous voyons également certains qui semblent moins bons - comme les traitements "5 C.siamea" et "8 maize" qui ont des rendements systématiquement faibles.

### Spécifier un modèle pour les données

La syntaxe et la fonction pour spécifier et ajuster un modèle ANOVA sont identiques à celles d'un modèle de régression linéaire. La seule différence est que la variable prédictive est une variable catégorielle (comme `treat`) plutôt qu'une variable quantitative (comme `striga`).
Donc - utilisons la même fonction `lm()`. Comme avant, lorsque nous l'exécutons seul, nous n'obtenons pas beaucoup de résultats utiles.

```{r anova_1,exercise=TRUE}
lm(yield~treat,data=fallow)
```

Ainsi, exactement comme dans la section précédente, nous souhaitons presque toujours sauver l'ajustement de notre modele dans un objet, puis utiliser diverses fonctions sur cet objet pour en savoir plus sur notre modèle.

```{r anova_mod, exercise=TRUE}
anova_mod<-lm(yield~treat,data=fallow)
```

`summary()` est toujours une des fonctions importantes a utiliser, car elle nous fournit de nombreuses in information
```{r anova_summary, exercise=TRUE}
summary(anova_mod)
```

La sortie est un tout petit peu différente de la sortie de notre régression linéaire simple. Beaucoup de choses sont identiques et ont la même interprétation. La valeur du R carré (84,9%) et l'ecart-type résiduel (0,4984) se trouvent aux mêmes endroits et ont les mêmes interprétations qu'auparavant.

Cependant, nous avons maintenant beaucoup plus de coefficients - et ceux-ci ont une signification légèrement différente lorsque l'on considère une variable catégorielle dans un modèle ANOVA. Ces coefficients représentent la différence entre les valeurs moyennes de chaque traitement et la valeur moyenne du niveau de référence. Le niveau de référence, par défaut, est le premier niveau de notre variable catégorielle lorsqu'il est trié par ordre alphabétique - dans ce cas, le traitement "1 S.sesban". L'ordonnée a l'origine (Intercept) représente la valeur moyenne dans cette categorie de référence.

Par conséquent, les p-values indiquées dans le résultat de `summary()` représentent des tests de significativité concernant des hypothèses qui ne nous intéressent peut-être pas directement. Le test pour l'ordonnée a l'origine teste l'hypothèse que la valeur moyenne du traitement 1 est 0. Ce n'est probablement pas une hypothèse utile. Les tests pour chacun des autres coefficients nous indiquent si chaque traitement est significativement différent du traitement 1. Ceci est utile, mais cela ne nous renseigne que sur les traitements par rapport a la categorie de référence. Il ne peut pas nous dire, par exemple, ce qu'il en est du traitement 2 par rapport au traitement 7, et il ne peut pas nous dire s'il existe un effet global du traitement. Bien que dans ce cas, la réponse à cela devrait être assez claire !

C'est pourquoi il est courant d'avoir recourt a un tableau ANOVA (analyse de variance) pour montrer s'il y a un effet global d'une variable catégorielle. L'hypothèse nulle dans ce tableau ANOVA est que tous les traitements ont le même rendement moyen. Une p-value significative, suggère donc qu'au moins un des traitements a un rendement moyen différent des autres. Nous pouvons accéder à au tableau ANOVA d'un modèle en utilisant la fonction `anova()`.


```{r anova_tab, exercise=TRUE}
anova(anova_mod)
```
Sans surprise, cela nous indique que nous avons un effet de traitement global significatif p = 3,144e-09. N'oubliez pas que c'est en notation scientifique; une autre façon d'écrire ce nombre serait 0.000000003144. Notez aussi que nous avions aussi cette p-value tout en bas de la sortie donnee par la fonction `summary()`.

### Conditions de validité

Nous avons toutes les mêmes conditions à vérifier que lorsque nous avons exécuté la régression linéaire plus tôt, et nous pouvons aussi évaluer le modèle en vérifiant les graphiques produits par la fonction `plot()`. La seule différence est que nous ne vérifions plus la linéarité, puisque nous avons 9 groupes distincts sans ordre apparent plutôt qu'une variable quantitative dont les valeurs sont clairement ordonnées. Mais sinon, nous voulons toujours vérifier s'il y a des problèmes d'hétérogénéité de variance, des valeurs aberrantes, des valeurs qui influencent beaucoup notre modele, et s'il y a de graves violations de la normalité des résidus.

```{r chks2, exercise=TRUE}
plot(anova_mod)
```

Encore une fois - il ne semble pas y avoir de gros problemes de validité. Cependant, comme avec la regession linéaire simple, nous pouvons envisager la possibilité que nous ayons une violation de la condition d'indépendance de nos observations. Cela dépend de la manière dont l'essai a été conçu:

Si nous avions un grand champ et que chacune des 36 parcelles était allouée aléatoirement aux 9 traitements, c'est a dire si nous sommes en présence d'un plan complètement aléatoire, alors il n'y a aucune raison de penser que la condition d'indépendance n'est pas respectée; toutes les parcelles proviennent alors de la même 'population'.

Par contre, si nous avions 4 'blocs' situés à différents endroits de notre station, et que chaque bloc avait une parcelle pour chaque traitement, un design experimental en blocs randomisés (Randomized Complete
Block), alors nous aurions une violation de l'indépendance, puisqu'il y aurait quatre 'blocs' physiques pour lesquels nous pouvons nous attendre à ce que les parcelles a l'interieur soient plus similaires que les parcelles entre les blocs. Que ce soit ou non un problème dépendra de la variabilité du terrain et autres conditions entre les blocs.

De meme, si nous avions 4 agriculteurs, et que chaque agriculteur utilise une parcelle pour chaque traitement, on a alors certainelemt une violation de la condition d'indépendance. Nous ne pouvons pas considérer les agriculteurs sont de simples replications !

Dans la section suivante, nous verrons comment utiliser des modèles linéaires mixtes pour prendre en compte la dépendance créée par nos designs experimentaux en bloc ou par des producteurs.


### Résultats du modèle et tests post-hoc

Dans les analyses de donnees de recherches en agriculture, il est très courant de mener des analyses post-hoc à partir de modèles ANOVA, souvent appelés 'mean separation'. Nous pouvons le faire en utilisant les packages `emmeans` et` multcomp`.

Cependant, nous voudrons peut-être d'abord créer des graphiques - montrant les valeurs moyennes de chacun de nos traitements et incluant des intervalles de confiance autour de ces estimations. Nous pouvons le faire en utilisant la fonction `emmip()`.

Cette fonction nécessite d'abord le nom du modèle (dans ce cas `anova_mod`), puis un tilde` ~ `suivi du nom de la variable de regroupement (dans notre cas `~treat`).

```{r plotCI, exercise=TRUE}
emmip(anova_mod,~treat)
```

Si nous voulons que les intervalles de confiance soient inclus dans le graphique, nous ajoutons également l'argument `CI = TRUE`
```{r plotCI2, exercise=TRUE}
emmip(anova_mod,~treat,CI=TRUE)
``` 

C'est une fonction tres utile pour créer des graphiques à partir de modèles lorsque nous augmentons la complexité de ces derniers, donc c'est vraiment bien de la connaitre !

Les données de ce graphique peuvent être extraites à l'aide de la fonction `emmeans()`. Nous n'avons pas besoin de demander des intervalles de confiance cette fois - ils apparaissent par defaut !

```{r estimates, exercise=TRUE}
emmeans(anova_mod,~treat)
```

Si vous vouliez personnaliser la sortie de `emmip` pour qu'elle soit mieux adaptee a vos présentations ou publications, alors vous pouvez obtenir les chiffres utilises pour l'obtenir avec la fonction `emmeans`, puis continuer la commande avec un "pipe", puis `ggplot()`. Il faudra juste d'abord convertir la sortie en un tableau de données avec la fonction `data.frame()`.

C'est une bonne occasion de vous parler de la geometrie `geom_errorbar()`. Cette `geom_` nécessite deux nouvelles 'esthétiques' que nous n'avons pas utilisées jusqu'à présent -` ymax` pour représenter le haut des barres d'erreur et `ymin` pour le bas des barres d'erreur.

```{r geom_err,exercise=TRUE}
emmeans(anova_mod,~treat) %>%
  data.frame() %>%
  ggplot(aes(y=emmean,x=treat,ymin=lower.CL,ymax=upper.CL))+
    geom_point()+
      geom_errorbar()
```



C'est à partir de la sortie de `emmeans()` que nous pouvons ensuite effectuer l'analyse "mean separation" en continuant la commande avec la fonction `cld()`. "cld" signifie "compact letter display", qui est un autre nom pour la "mean separation" (separation des moyennes).


```{r cld, exercise=TRUE}
emmeans(anova_mod,~treat) %>%
  cld()
```
Par défaut, `cld()` compare les moyennes des groupes utilisant la méthodology de "Tukey", mais d'autres methodologies sont aussi disponibles si vous le souhaitez. L'idée est que nous pouvons conclure que tous les traitements qui n'ont pas de chiffres en communs dans la colonne `.group` peuvent être considérés comme significativement différents. Nous pouvons donc voir ici que le traitement 1 a un rendement significativement plus élevé que tous les autres traitements (car aucun autre traitement partage le chiffre "4" dans la colonne .groupe); le traitement 2 a un rendement significativement plus élevé que les traitements 8,5 et 6 (car ces traintement ne partagent pas le chiffre "3"), et ainsi de suite.

J'ai tendance à trouver qu'en recherche en agriculture les gens preferent voire des lettres plutot que des chiffres. Nous pouvons avoir ca en ajoutant l'option `Letters=letters`. Attention a la casse de cette option !


```{r cld_lets, exercise=TRUE}
emmeans(anova_mod,~treat) %>%
  cld(Letters=letters)
```

Si on le souhaitait, on pourrait ajouter ces lettres sur notre graphique avec les barres d'erreur en utilisant une autre geometrie : ` geom_text` qui permet d'ajouter du texte sur un graphique. Cela nécessite d'utiliser une autre esthétique : `label` pour indiquer la colonne contenant les étiquettes de texte à afficher.

```{r cld_plot,exercise=TRUE}
emmeans(anova_mod,~treat) %>%
  cld(Letters=letters) %>% 
  data.frame() %>%
  ggplot(aes(y=emmean,x=treat,ymin=lower.CL,ymax=upper.CL,label=.group))+
    geom_point()+
      geom_errorbar()+
        geom_text()
```
Le texte ajoute au graphique est positionne suivant les coordonnees definies par les esthetiques x et y, et de ce fait il est un peu confondu avec les points. On peut cependent deplacer un peu les étiquettes en utilisant les arguments `nudge_x` et/ou` nudge_y`. Par example pour un petit deplacement sur la gauche, on peu donner un faible valeur negative (ici je mets -0.2) a l'argument `nudge_x`

```{r cld_plot2,exercise=TRUE}
emmeans(anova_mod,~treat) %>%
  cld(Letters=letters) %>% 
  data.frame() %>%
  ggplot(aes(y=emmean,x=treat,ymin=lower.CL,ymax=upper.CL,label=.group))+
    geom_point()+
      geom_errorbar()+
        geom_text(nudge_x=-0.2)
```

## Modèle linéaire mixte et généralisé

Comme nous l'avons dit avant, il ne semble pas raisonnable d'accepter la condition d'indépendance entre nos observations.
Ceci est très courant dans les analyses de données en recherche en agriculture ou l'on a souvent des designs experimentaux avec une certaines structure (souvent en blocs) ou des experiences menés chez plusieurs agriculteurs ou les observations collectees par un agriculteur ne peuvent pas etre considerées comme indépendantes, car l'agriculteur travail avec ses propres techniques dans sur un champ situe a un endroit particulier etc. Dans ce genre de cas, nous devons passer d'un modèle linéaire relativement "simple" à un "modèle linéaire mixte" qui est appelé de cette facon car il contient des effets "fixes" (variables qui nous intéressent) et des effets "aléatoires" (variables décrivant la structure ou le regroupement des observations dans les données) Vous pouvez voir une présentation de la théorie et de l'application de modèles linéaires mixtes en agriculture ici: https://www.esalq.usp.br/departamentos/lce/arquivos/aulas/2012/LCE5872/MixedModelsPiracicaba.pdf

Mathématiquement, c'est un peu plus compliqué que ce que l'on a vu avant, mais dans R, ce n'est pas si différent, et vous verrez que l'on va utiliser une bonne partie des fonctions que l'on a utilisé dans les sections précédentes. Nous utiliserons les mêmes packages, mais ajouterons maintenant aussi le package `lmertest` pour pouvoir ajuster un modèle de "régression linéaire à effets mixtes" (`lmer()`). Ce genre de modeles est tres flexible et peut nous permettre de prendre en compte n'importe lequel des modèles expérimentaux standards utilisés en agriculture, tant que nous avons a disposition les données nécessaires pour definir la structure de nos experiences.

Mais ce genre de modeles est aussi tres adapte pour modeliser des données d'essais et d'enquêtes pour lesquels nous avons d'autres types de regroupement (agriculteurs dans le même village) ou des pseudo-réplications (le même agriculteur a plusieurs parcelles). Il peut être difficile de déterminer exactement comment structurer le code pour votre modèle, donc n'ayez pas peur de demander de l'aide si vous n'êtes pas sûr! Il y a des ressources à la fin de ce document qui couvrent bon nombre des designs experimentaux courants en agriculture (notez que les fonctions utilisées restent les mêmes quelque soit le design).


### Ajustement du modèle

Nos donnees proviennent d'un design RCBD (design en blocs complets randomisés) avec 4 blocs et 9 traitements. Nous avons donc un facteur de traitement, "treat", et un facteur indiquant la disposition en bloc, "rep". Si nous voulons prendre en compte cette structure de disposition en blocs répétés, nous ne pouvons plus utiliser la fonction “lm” et nous devons à la place inclure le facteur “rep” dans la spécification d'un modèle linéaire à effets mixtes en utilisant la fonction `lmer()`. La syntaxe utilisee pour cette fonction est similaire a celle de `lm()`, mais il faut dans notre formule ajouter un '+', puis indiquer la structure en écrivant entre parenthese `1|variable_de_structure`, donc dans ce cas on va ecrire `+ (1|rep)`. Ensuite, le reste du code du modèle est le même qu'avant :

```{r glm, exercise=TRUE}
mod_mixte<-lmer(yield~treat+(1|rep),data=fallow)
```

Comme avant, pour avoir des informations utiles sur l'ajustement de notre modèle, nous devons utiliser des fonctions supplémentaires - nous pouvons commencer par `summary()`.

```{r glm2, exercise=TRUE}
summary(mod_mixte)
```
La sortie est un peu différente pour un modèle à effets mixtes, bien que la plupart des choses restent très similaires. Le tableau des coefficients est le même que précédemment et a la même interprétation. La sortie supplémentaire montrant la corrélation entre les effets fixes n'est pas très utile pour nous ici, car dans cette expérience, tous les traitements sont répliqués le même nombre de fois.

L'ecart-type de l'erreur résiduelle est toujours la, mais à un endroit différent - cette valeur est 0,4843 qui peut être trouvée dans le tableau "Random effects" (Effets aléatoires). Ce type de modèle décompose la variance en ce qui peut être expliqué par notre structure de dependance (le terme `rep`) et le reste de la variance résiduelle. La comparaison de la quantite de variance expliquée par chaque composante peut être utile pour nous donner une idée de l'importance de notre facteur "rep" sur nos resulats. Dans notre cas, la quantité de variance expliquée par `rep` (écart-type = 0,1175) est assez faible par rapport à la variance résiduelle (écart-type = 0,4843).

Une chose qui manque lorsque nous comparons à la sortie de l'exécution de `summary` après un `lm` est la valeur du R carré. On peut cependant l'obtenir en utilisant la fonction `r.squaredGLMM` qui provient du package `MuMIn`.

```{r r2, exercise=TRUE}
r.squaredGLMM(mod_mixte)
```
R nous donne alors deux versions de R-carré - le R carré marginal `R2m`- qui ne montre que la variance expliquée par les "effets fixes" dans ce cas le terme de traitement. Et on a aussi le "conditional" R carré `R2c` qui prend en compte à la fois les effets fixes et aléatoires - donc inclut à la fois `rep` et `treat`. Ainsi, nous pouvons voir que 81% de la variabilité du rendement est expliquée par les différents traitements, et cela augmente à 82,3% si nous incluons également le rep. La difference est assez faible.

Pour obtenir un tableau ANOVA - nous pouvons comme avant utiliser `anova(model)`

```{r glm_anova, exercise=TRUE}
anova(mod_mixte)
```
Le tableau ANOVA n'inclut que les effets fixes - nous montrant une p-value très significative (6.98e-09) pour le traitement, indiquant qu'il semble en effet y a avoir des différences entre nos traitements. Nous pourrions également tester si nos effets aléatoires influencent significativement les rendements en utilisant `ranova`.

```{r ranova, exercise=TRUE}
ranova(mod_mixte)
```

Cela ne nous montre pas un effet significatif des différents `reps` que nous avons dans les données (p-value=0.6038). Comme cette variable décrit la structure de nos données, ce n'est pas quelque chose qui nous intéresse particulièrement. En general avec les variables structurelles, nous voulons simplement tenir compte du fait qu'elles peuvent avoir impact sur notre variable reponse. Il reste cependant interessant de savoir que dans ce cas precis, la structure en bloc ne semble pas avoir beaucoup d'impact. Probablement que le champ utilise est assez homogene de sorte que les differentes parecelles utilisees comme bloc reste tres similaires entre elles. Notez que cette non-signification suggérerait que l'on peut probablement avoir confiance en les résultats que nous avons obtenus avant en utilisant la fonction “lm”, bien que ceux-ci ne prenaient pas en compte la structure de design en blocs.

### Vérifiez le modèle

Nous avons également plusieurs des mêmes conditions à vérifier avec ce modèle, bien que les fonctions ici fonctionnent un peu différemment.

La fonction `plot()` tracera uniquement les valeurs ajustées du modèle (les rendements moyens attentdus si notre modele etait bon) par rapport aux valeurs residuelles.


```{r glm_plt, exercise=TRUE}
plot(mod_mixte)
```
Mais nous pouvons vérifier la plupart des conditions clés sur ce seul graphique. On peut y verifier la condition d'homogeneite de variance en regardant si les points sont verticalement plus rapproches a certains endroits de l'axe x qu'a d'autres. Souvent lorsque l'on a un probleme d'homogeneite, on obtient un graphique ou les points forment une sorte de triangle. Ici, ce n'est pas le cas, donc la condition d'homogeneite de la variance semble satisfaite.

Nous pouvons également voir qu'il n'y a pas de valeurs extrêmes dans les résidus qui pourraient potentiellement causer des problèmes sur la validité de nos conclusions (points ayant une forte influence sur les parametres de nos modeles)

Pour évaluer l'hypothèse de normalité approximative, nous pouvons produire le même graphique que précédemment si nous extrayons les résidus et utilisons la fonction `qqnorm`. Cela nous montre à quel point les résidus suivent une distribution normale - s'il y a des écarts importants et systématiques par rapport à la droite, nous pouvons alors envisager d'utiliser un autre type de modele avec une distribution differents. La façon la plus élégante de faire ce graphique est d'utiliser des pipe - d'abord pour obtenir les résidus et ensuite pour demander a R d'utiliser ces résidus dans la fonction `qqnorm`..

```{r qqplot, exercise=TRUE}
mod_mixte %>%
   resid() %>%
      qqnorm() 
```
Dans notre cas, la condition de normalite des résidus semble a peu pres ok.

### Tests de post-hoc

Les fonctions que nous avons vues dans la section précédente, `emmip` et `emmeans` et `cld` fonctionnent toutes exactement de la même manière. Tout ce que nous devons changer est le nom de notre objet pour le premier argument, et nous obtenons les graphiques avec des intervalles de confiance et l'analyse de "mean separation".

```{r emmip_glm, exercise=TRUE}
emmip(mod_mixte,~treat,CIs = TRUE)
```


```{r cldglm, exercise=TRUE}
emmeans(mod_mixte, ~treat) %>%
  cld(Letters=letters)
```

Dans cette sortie, les groupes partageant une lettre dans la colonne `.group` ne sont pas statistiquement différents les uns des autres, comme auparavant.

En utilisant l'exemple de la section précédente, voyez si vous pouvez écrire le code pour créer un graphique montrant les résultats du modèle `lmer`, y compris les lettres et les barres d'erreur.

```{r cldplt, exercise=TRUE}

```

```{r cldplt-solution}
emmeans(mod_mixte, ~treat) %>%
  cld(Letters=letters)  %>% 
  data.frame() %>%
  ggplot(aes(y=emmean,x=treat,ymin=lower.CL,ymax=upper.CL,label=.group))+
    geom_point()+
      geom_errorbar()+
        geom_text(nudge_x=-0.2)
   
```

### Choix du modèle

Finalement, notre modèle ajusté en utilisant un modèle linéaire mixte, avec un effet aléatoire pour tenir compte des blocs, en utilisant `lmer` a fourni des résultats presque identiques au modèle linéaire standard ajusté en utilisant `lm`. Mais cela ne sera pas tout le temps le cas. Il se pourra aussi parfois que les conditions de validite, notamment l'homogeneite de la variance ou la normalite des residus ne soit pas respecte. Dans ce cas il peut etre utilse d'aller vers les modeles lineaires mixtes generalises. Ces modeles sont une extension permettant de prendre en compte des distibutions un peu differentes pour votre variable reponse. Vous avez peut-etre entendu parler des régressions de Poisson lorsque votre variable reponse est une variable de dénombrement. La régression logistique fait aussi parti de cette classe de modeles. On l'utilise lorsque notre reponse une variable binaires (0 ou1, oui ou non, etc.). Mais la syntaxe pour ajuster tous ces modeles est encore une fois assez similaire et on peut utilsier pour la plupart les mêmes fonctions. Seulement la fonction principale a utiliser devient `glmer()` (ou `glm()` lorsque vous n'ajoutez pas d'effets aleatoire).

Et peu importe que nous ayons des variables prédictives quantitatives, qualitatives, ou un mélange des deux. Tous ces modèles sont ajustés et interprétés par R de la même manière.




## Principes méthodologiques

Il existe toujours de nombreuses façons différentes de faire tout ce que nous avons fait ici dans R. Si vous recherchez des conseils en ligne sur la façon d'analyser des deisgns particulièrs, vous trouverez peut-être de nombreuses options différentes pour analyser des design en "parcelles fractionnées" ou des données "d'enquête". C'est toujours une bonne idée de demander de l'aide lorsque vous commencez à analyser des données si vous n'êtes pas sûr de la façon dont elles doivent être analysées - vous devez vous assurer que vous analysez les données de manière à vous permettre de répondre aux questions qui sont les plus pertinentes pour vous. C'est le grand avantage d'utiliser l'approche montrée dans ce tutoriel. Les fonctions  `lm()` et `lmer()` (et leurs extensions `glm()` et `glmer()`) sont incroyablement flexibles et peuvent être utilisées dans de nombreuses situations différentes. Les 


## Exercices

Comme dans le dernier module, c'est maintenant à vous d'utiliser RStudio pour effectuer les exercices sur votre propre ordinateur.

Vous pouvez télécharger les fichiers dont vous avez besoin [en cliquant sur ce lien ici](https://github.com/stats4sd/R-course-FR-06-StatAnalysis2/blob/main/Exercises.zip?raw=true)

Assurez-vous de les décompresser dans un nouveau dossier, puis démarrez un nouveau fichier de projet basé sur ce dossier, comme nous l'avons appris précédemment.

Vous devrez probablement installer certains des packages utilisés avant de continuer. Assurez-vous de les avoir installés et chargés, en exécutant le premier bloc de code, avant d'essayer de répondre aux questions.


## Autres exemples d'analyse

Vous pouvez trouver plus d'exemples dans un style similaire ici:
https://shiny.stats4sd.org/AgAnalysis/

Un ensemble plus large d'analyses agricoles peut être vu ici:
https://rstats4ag.org/

Il existe également des packages spécifiques pour d'autres types d'analyses de donnees issues de recherches em agriculture, comme le package `agricolae`. Il existe un tutoriel assez complet sur les fonctions incluses dans ce package ici:
https://pbil.univ-lyon1.fr/CRAN/web/packages/agricolae/vignettes/tutorial.pdf


